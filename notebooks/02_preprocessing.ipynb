{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis - Data Preprocessing\n",
    "\n",
    "This notebook handles text preprocessing and feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:37.296104Z",
     "iopub.status.busy": "2025-11-23T23:23:37.295962Z",
     "iopub.status.idle": "2025-11-23T23:23:38.107052Z",
     "shell.execute_reply": "2025-11-23T23:23:38.106613Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from src.utils import load_imdb_data, split_data, ensure_dir\n",
    "from src.preprocessing import (\n",
    "    clean_text, tokenize_text, preprocess_reviews,\n",
    "    create_tfidf_features, encode_labels\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:38.108542Z",
     "iopub.status.busy": "2025-11-23T23:23:38.108434Z",
     "iopub.status.idle": "2025-11-23T23:23:38.452471Z",
     "shell.execute_reply": "2025-11-23T23:23:38.452079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/IMDB Dataset.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 reviews\n",
      "Columns: ['review', 'sentiment']\n",
      "\n",
      "Dataset shape: (50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = load_imdb_data('../data/IMDB Dataset.csv')\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Cleaning Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:38.465032Z",
     "iopub.status.busy": "2025-11-23T23:23:38.464926Z",
     "iopub.status.idle": "2025-11-23T23:23:38.477004Z",
     "shell.execute_reply": "2025-11-23T23:23:38.476683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original review:\n",
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Cleaned review:\n",
      "one of the other reviewers has mentioned that after watching just oz episode you will be hooked they are right as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word it is called oz as that is the nickname given to\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Tokens (first 50): ['one', 'reviewers', 'mentioned', 'watching', 'oz', 'episode', 'hooked', 'right', 'exactly', 'happened', 'first', 'thing', 'struck', 'oz', 'brutality', 'unflinching', 'scenes', 'violence', 'set', 'right', 'word', 'go', 'trust', 'show', 'faint', 'hearted', 'timid', 'show', 'pulls', 'punches', 'regards', 'drugs', 'sex', 'violence', 'hardcore', 'classic', 'use', 'word', 'called', 'oz', 'nickname', 'given', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'focuses', 'mainly', 'emerald']\n",
      "\n",
      "Total tokens: 164\n"
     ]
    }
   ],
   "source": [
    "# Show cleaning examples\n",
    "sample_review = df['review'].iloc[0]\n",
    "\n",
    "print(\"Original review:\")\n",
    "print(sample_review[:500])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "cleaned = clean_text(sample_review)\n",
    "print(\"Cleaned review:\")\n",
    "print(cleaned[:500])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "tokens = tokenize_text(cleaned)\n",
    "print(f\"Tokens (first 50): {tokens[:50]}\")\n",
    "print(f\"\\nTotal tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:38.478306Z",
     "iopub.status.busy": "2025-11-23T23:23:38.478234Z",
     "iopub.status.idle": "2025-11-23T23:23:57.302792Z",
     "shell.execute_reply": "2025-11-23T23:23:57.302379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "      <td>one reviewers mentioned watching oz episode ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there is a family where a little boy...</td>\n",
       "      <td>[basically, family, little, boy, jake, thinks,...</td>\n",
       "      <td>basically family little boy jake thinks zombie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei is love in the time of money is ...</td>\n",
       "      <td>[petter, mattei, love, time, money, visually, ...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production the filming tech...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there is a family where a little boy...   \n",
       "4  petter mattei is love in the time of money is ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [one, reviewers, mentioned, watching, oz, epis...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, family, little, boy, jake, thinks,...   \n",
       "4  [petter, mattei, love, time, money, visually, ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  one reviewers mentioned watching oz episode ho...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically family little boy jake thinks zombie...  \n",
       "4  petter mattei love time money visually stunnin...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing pipeline\n",
    "df_processed = preprocess_reviews(df)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:57.304069Z",
     "iopub.status.busy": "2025-11-23T23:23:57.303993Z",
     "iopub.status.idle": "2025-11-23T23:23:57.306239Z",
     "shell.execute_reply": "2025-11-23T23:23:57.305869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed texts:\n",
      "\n",
      "1. Original length: 1761 chars\n",
      "   Processed length: 1115 chars\n",
      "   Token count: 164\n",
      "   Sentiment: positive\n",
      "\n",
      "2. Original length: 998 chars\n",
      "   Processed length: 660 chars\n",
      "   Token count: 86\n",
      "   Sentiment: positive\n",
      "\n",
      "3. Original length: 926 chars\n",
      "   Processed length: 578 chars\n",
      "   Token count: 85\n",
      "   Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Check preprocessing results\n",
    "print(\"Sample processed texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n{i+1}. Original length: {len(df['review'].iloc[i])} chars\")\n",
    "    print(f\"   Processed length: {len(df_processed['processed_text'].iloc[i])} chars\")\n",
    "    print(f\"   Token count: {len(df_processed['tokens'].iloc[i])}\")\n",
    "    print(f\"   Sentiment: {df['sentiment'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:23:57.307445Z",
     "iopub.status.busy": "2025-11-23T23:23:57.307384Z",
     "iopub.status.idle": "2025-11-23T23:24:06.731684Z",
     "shell.execute_reply": "2025-11-23T23:24:06.731210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features with max_features=5000, ngram_range=(1, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (50000, 5000)\n",
      "Vocabulary size: 5000\n",
      "\n",
      "Feature matrix shape: (50000, 5000)\n",
      "Matrix sparsity: 98.36%\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF feature matrix\n",
    "X_tfidf, vectorizer = create_tfidf_features(\n",
    "    df_processed['processed_text'].tolist(),\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_tfidf.shape}\")\n",
    "print(f\"Matrix sparsity: {(1 - X_tfidf.nnz / (X_tfidf.shape[0] * X_tfidf.shape[1])):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:24:06.732921Z",
     "iopub.status.busy": "2025-11-23T23:24:06.732842Z",
     "iopub.status.idle": "2025-11-23T23:24:06.739844Z",
     "shell.execute_reply": "2025-11-23T23:24:06.739483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features by total TF-IDF score:\n",
      " 1. movie                - Score: 2004.35\n",
      " 2. film                 - Score: 1763.15\n",
      " 3. one                  - Score: 1430.95\n",
      " 4. like                 - Score: 1250.55\n",
      " 5. good                 - Score: 1124.27\n",
      " 6. would                - Score: 1096.33\n",
      " 7. time                 - Score: 979.74\n",
      " 8. see                  - Score: 968.50\n",
      " 9. even                 - Score: 957.73\n",
      "10. really               - Score: 956.71\n",
      "11. story                - Score: 955.38\n",
      "12. well                 - Score: 886.26\n",
      "13. great                - Score: 872.34\n",
      "14. bad                  - Score: 863.48\n",
      "15. much                 - Score: 833.52\n",
      "16. could                - Score: 832.50\n",
      "17. people               - Score: 809.90\n",
      "18. get                  - Score: 808.86\n",
      "19. movies               - Score: 788.61\n",
      "20. first                - Score: 771.80\n"
     ]
    }
   ],
   "source": [
    "# Show top features by TF-IDF score\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = X_tfidf.sum(axis=0).A1\n",
    "top_features_idx = tfidf_scores.argsort()[-20:][::-1]\n",
    "\n",
    "print(\"Top 20 features by total TF-IDF score:\")\n",
    "for i, idx in enumerate(top_features_idx, 1):\n",
    "    print(f\"{i:2d}. {feature_names[idx]:20s} - Score: {tfidf_scores[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:24:06.741005Z",
     "iopub.status.busy": "2025-11-23T23:24:06.740938Z",
     "iopub.status.idle": "2025-11-23T23:24:06.744604Z",
     "shell.execute_reply": "2025-11-23T23:24:06.744261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: (50000,)\n",
      "Positive samples: 25000 (50.0%)\n",
      "Negative samples: 25000 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "# Encode sentiment labels\n",
    "y = encode_labels(df['sentiment'])\n",
    "\n",
    "print(f\"Label shape: {y.shape}\")\n",
    "print(f\"Positive samples: {y.sum()} ({y.mean():.1%})\")\n",
    "print(f\"Negative samples: {len(y) - y.sum()} ({1 - y.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:24:06.745599Z",
     "iopub.status.busy": "2025-11-23T23:24:06.745532Z",
     "iopub.status.idle": "2025-11-23T23:24:06.764343Z",
     "shell.execute_reply": "2025-11-23T23:24:06.763944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data: 80% train, 20% test\n",
      "Train set: 40000 samples\n",
      "Test set: 10000 samples\n",
      "Train positive ratio: 50.00%\n",
      "Test positive ratio: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    X_tfidf, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T23:24:06.765524Z",
     "iopub.status.busy": "2025-11-23T23:24:06.765458Z",
     "iopub.status.idle": "2025-11-23T23:24:08.518305Z",
     "shell.execute_reply": "2025-11-23T23:24:08.517841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer saved to ../models/tfidf_vectorizer.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test data saved to ../models/train_test_data.npz\n"
     ]
    }
   ],
   "source": [
    "# Ensure models directory exists\n",
    "ensure_dir('../models')\n",
    "\n",
    "# Save vectorizer\n",
    "with open('../models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(\"Vectorizer saved to ../models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save train/test splits\n",
    "np.savez_compressed(\n",
    "    '../models/train_test_data.npz',\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    ")\n",
    "print(\"Train/test data saved to ../models/train_test_data.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Preprocessing Steps Completed:\n",
    "1. ✅ Text cleaning (lowercase, remove HTML, special chars)\n",
    "2. ✅ Tokenization with stopword removal\n",
    "3. ✅ TF-IDF vectorization (5000 features, unigrams + bigrams)\n",
    "4. ✅ Label encoding (positive=1, negative=0)\n",
    "5. ✅ Train/test split (80/20, stratified)\n",
    "\n",
    "### Dataset Statistics:\n",
    "- **Training samples**: 40,000\n",
    "- **Test samples**: 10,000\n",
    "- **Features**: 5,000 TF-IDF features\n",
    "- **Matrix sparsity**: ~99% (typical for text data)\n",
    "\n",
    "### Next Steps:\n",
    "- Train Naive Bayes classifier\n",
    "- Train Logistic Regression classifier\n",
    "- Evaluate and compare models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
